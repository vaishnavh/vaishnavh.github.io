<html>
  <head>
    <meta content=' - Vaishnavh Nagarajan' name='title' />
    <meta content=' - Vaishnavh Nagarajan' name='og:title' />
    <title>Vaishnavh Nagarajan</title>
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-55182625-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-55182625-3');
</script>


<link href='../images/fav.ico' rel='shortcut icon'>
<link href='http://fonts.googleapis.com/css?family=Teko|Dosis:400,800|Economica|Josefin+Sans|Oswald|Indie+Flower|Pacifico|Roboto' rel='stylesheet' type='text/css'><link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css' />
<link href='../stylesheets/style.css' rel='stylesheet' type='text/css' />
<link href='../stylesheets/syntax.css' rel='stylesheet' type='text/css' />
<link href='../stylesheets/responsive.css' rel='stylesheet' type='text/css' />
<!-- - -->
<script src='../javascripts/jquery.js' type='text/javascript'></script>
<script src='../javascripts/pd.js' type='text/javascript'></script>
<script src='../javascripts/basics.js' type='text/javascript'></script>
<script type="text/javascript" src="https://www.google.com/jsapi"></script>
<!-- - -->
<meta content='width=device-width, initial-scale=1.0, user-scalable=no' name='viewport'>
<meta content='text/html; charset=utf-8' http-equiv='content-type' />
<meta content="http://muan.co/images/og.png" property="og:image" />
<meta content="" property="fb:app_id" />

  <meta content='http://localhost:4000' property='og:url' />
  <meta content="Welcome to my personal website!" property='og:description' />
  <meta content="blog" property="og:type" />

<!-- - -->
<script type='text/javascript'>
  //<![CDATA[
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', '']);
    _gaq.push(['_trackPageview']);
    
    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  //]]>
</script>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1&appId=604714799556697";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>


<!-- for mathjax support -->



<!-- for mathjax support -->



  </head>
  <body>
    <header>
<!--<br><p>Vaishnavh Nagarajan</p>-->
</header>
    <div id='container'>
      <div class="content">
          <section class='post'>
            <h1></h1>
            <img src="../images/me.jpg" height=28% style="padding: 20px 40px 40px 60px;" align="left"></img>

<p style="font-family: Futura; font-weight:500; font-size:25">VAISHNAVH NAGARAJAN</p>

<p>Research Scientist<br />
Google, New York<br />
<strong>E-Mail</strong>: vaishnavh at google.com<br />
<i>He/Him/His</i></p>

<p><a href="../VaishnavhNagarajanResume.pdf"><b>Resume</b></a> | <a href="https://scholar.google.com/citations?hl=en&user=LrsjJfwAAAAJ&view_op=list_works&sortby=pubdate"><b>Google Scholar</b></a></p>

<p><a href="https://twitter.com/_vaishnavh?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @_vaishnavh</a><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p><br />
<br /></p>

<h2 id="about-me">ABOUT ME</h2>

<p>I am a research scientist at Google. I am interested in the theoretical foundations of machine learning. I’m particularly excited about understanding when and why modern machine learning algorithms work (or do not work). While my PhD <a href="https://arxiv.org/abs/2110.08922 ">thesis</a> was on 
 explaining why deep networks generalize well, my other works includes when/why models fail outside of distribution, and when/why GANs converge to the desired saddle point.</p>

<p>Prior to this I graduated with a PhD from <a href="https://www.csd.cs.cmu.edu">the Computer Science Department</a> of <a href="http://www.cmu.edu">Carnegie Mellon University (CMU)</a>. I was extremely fortunate to be advised by <a href="http://zicokolter.com">Zico Kolter</a>. 
I completed my undergraduate studies in <a href="http://www.cse.iitm.ac.in/">the Department of Computer Science and Engineering</a> at <a href="http://www.iitm.ac.in/">the Indian Institute of Technology, Chennai, </a> India. Here I was advised by <a href="http://www.cse.iitm.ac.in/~ravi/">Balaraman Ravindran</a> with whom I worked in reinforcement learning.</p>

<hr />

<h2 id="updates">UPDATES</h2>
<ul>
  <li>Jan 2022: Spotlight paper at ICLR ‘22 on a <a href="https://arxiv.org/abs/2106.13799">technique</a> that uses  unlabeled data to predict the generalization error of deep networks with remarkable precision!.</li>
  <li>Oct 2021: Excited to join as a research scientist at Google NYC!</li>
  <li>Jan 2021: Two papers accepted at ICLR ‘21, <a href="https://arxiv.org/abs/2010.15775">one</a> on out-of-distribution generalization and the
<a href="https://arxiv.org/abs/2011.01205">other</a> on local explanability.</li>
</ul>

<hr />

<h2 id="publications--google-scholar">PUBLICATIONS  (<a href="https://scholar.google.com/citations?hl=en&amp;user=LrsjJfwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Google Scholar</a>)</h2>

<p><br /></p>

<h3 id="full-conference-papers">Full Conference Papers</h3>

<ul>
  <li><span style="color:#c25c0a"><strong>Assessing Generalization via Disagreement</strong></span>,<br />
<em>International Conference on Learning Representations (ICLR) 2022</em>,<br />
(Double first author) Yiding Jiang*, Vaishnavh Nagarajan*, Christina Baek, J. Zico Kolter<br />
<span style="background-color: #ffce00"><strong>Accepted for Spotlight presentation</strong></span>      <br />
<a href="https://arxiv.org/abs/2106.13799">[arxiv]</a>
<a href="../talks/GDE_poster.pdf">[Poster]</a>
    <ul>
      <li>Also accepted at ICML ‘21 Workshop on Overparameterization: Pitfalls &amp; Opportunities</li>
    </ul>
  </li>
</ul>
<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Understanding the failure modes of out-of-distribution generalization</strong></span>,<br />
<em>International Conference on Learning Representations (ICLR) 2021</em>,  <br />
Vaishnavh Nagarajan, Anders Andreassen and Behnam Neyshabur<br />
<a href="https://arxiv.org/abs/2010.15775">[arxiv]</a>
<a href="../talks/ood_poster.pdf">[Poster]</a>
    <ul>
      <li><strong>Invited</strong> poster presentation at <em>Conceptual Understanding of Deep Learning Workshop</em>, Google Algorithms Workshop Series, 2021.</li>
    </ul>
  </li>
</ul>
<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>A Learning Theoretic Perspective on Local Explainability</strong></span>,  <br />
<em>International Conference on Learning Representations (ICLR) 2021</em>,  <br />
(Double first author) Jeffrey Li*, Vaishnavh Nagarajan*, Gregory Plumb and Ameet Talwalkar<br />
<a href="https://arxiv.org/abs/2011.01205">[arxiv]</a>
<a href="../talks/interpretability_theory_poster.pdf">[Poster]</a></li>
</ul>

<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Provably Safe PAC-MDP exploration using analogies</strong></span>,<br />
<em>International Conference on
Artificial Intelligence and Statistics (AISTATS) 2021</em><br />
Melrose Roderick, Vaishnavh Nagarajan and J. Zico Kolter <br />
<a href="https://arxiv.org/abs/2007.03574">[arxiv]</a></li>
</ul>

<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Uniform convergence may be unable to explain generalization in deep learning</strong></span>,<br />
<em>Neural Information Processing Systems (NeurIPS) 2019</em><br />
Vaishnavh Nagarajan and J. Zico Kolter <br />
<span style="background-color: #ffce00"><strong>Winner of The Outstanding New Directions Paper Award</strong></span><br />
<span style="background-color: #ffce00"><strong>Accepted for Oral presentation, 0.54% acceptance</strong></span><br />
<a href="https://arxiv.org/abs/1902.04742">[arxiv]</a> 
 <a href="../talks/neurips19_uc_slides.pdf">[NeurIPS 19 oral slides]</a>
 <a href="../talks/neurips19_uc_poster.pdf">[Poster]</a>
 <a href="https://locuslab.github.io/2019-07-09-uniform-convergence/">[Blogpost]</a>
 <a href="https://github.com/locuslab/uniform-convergence-NeurIPS19">[Code]</a>
 <a href="../errata/index.html#uc">[Errata]</a><br />
Also accepted for <span style="background-color: #ffce00"><strong>spotlight talk</strong></span> at:
    <ul>
      <li><a href="https://sites.google.com/view/icml2019-generalization/home ">ICML ‘19 Workshop</a> on Understanding and Improving Generalization in Deep Learning</li>
      <li><a href="https://www.ias.edu/math/wtdl">IAS/Princeton Workshop</a> on Theory of Deep Learning. <a href="https://video.ias.edu/theorydeeplearning/2019/1016-Various">[Video]</a></li>
    </ul>
  </li>
</ul>

<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience</strong></span>,<br />
<em>International Conference of Learning Representations (ICLR) 2019</em><br />
Vaishnavh Nagarajan and J. Zico Kolter <br />
<a href="https://openreview.net/forum?id=Hygn2o0qKX">[Openreview]</a> 
 <a href="https://s3.amazonaws.com/postersession.ai/0c93bed3-a55e-4c48-b3a8-bf47305cb2ef.jpg">[Poster]</a>
 <a href="../errata/index.html#pac-bayes">[Errata]</a></li>
</ul>

<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Gradient descent GAN optimization is locally stable</strong></span>,<br />
<em>Neural Information Processing Systems (NeurIPS) 2017</em> <br />
Vaishnavh Nagarajan and J. Zico Kolter<br />
<span style="background-color: #ffce00"><strong>Accepted for Oral presentation, 1.2% acceptance</strong></span> <br />
<a href="https://arxiv.org/abs/1706.04156">[arxiv]</a> <a href="../talks/gan-stability-cmu.pdf">[1hr talk - slides]
</a> <a href="../talks/nips17_oral.pdf">[NeurIPS Oral - Slides]
</a> <a href="../talks/nips17_poster.pdf">[Poster]
</a> <a href="https://www.youtube.com/watch?v=9gQt6Vqb854">[3 min video]</a>
<a href="https://github.com/locuslab/gradient_regularized_gan">[Code]</a></li>
</ul>
<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Lifelong Learning in Costly Feature Spaces</strong></span>,<br />
<em>Algorithmic Learning Theory (ALT) 2017</em><br />
with Maria-Florina Balcan and Avrim Blum<br />
Also an <strong>invited</strong> journal publication in Theoretical Computer Science (TCS)<br />
 <a href="https://arxiv.org/abs/1706.10271">[arxiv]</a><a href="../talks/alt2017_talk.pdf">[Slides]</a></li>
</ul>
<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Learning-Theoretic Foundations of Algorithm Configuration for Combinatorial Partitioning Problems</strong></span>,<br />
<em>Conference On Learning Theory (COLT), 2017</em><br />
with Maria-Florina Balcan, Ellen Vitercik and Colin White<br />
<a href="https://arxiv.org/abs/1611.04535">[arxiv]</a>
<a href="../talks/simons-talk.pdf">[Slides]</a>
<a href="https://www.youtube.com/watch?v=9O1Tc2pp0E0">[Talk]</a></li>
</ul>
<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Every team deserves a second chance: Identifying when things go wrong</strong></span>,<br />
<em>Autonomous Agents and Multiagent Systems (AAMAS) 2015</em><br />
(Double 1st author) Vaishnavh Nagarajan*, Leandro S. Marcolino* and Milind Tambe <br />
<a href="../papers/aamas15.pdf">[PDF]</a>   <a href="../papers/aamas15-ap.pdf">[Appendix]</a></li>
</ul>

<p><br /></p>

<h3 id="workshop-papers">Workshop Papers</h3>

<ul>
  <li><span style="color:#c25c0a"><strong>Theoretical Insights into Memorization in GANs</strong></span>,<br />
<em>Neural Information Processing Systems (NeurIPS) 2017 - Integration of Deep Learning Theories Workshop</em><br />
Vaishnavh Nagarajan, Colin Raffel, Ian Goodfellow.<br />
<a href="../papers/GAN_memorization.pdf">[PDF]</a></li>
</ul>

<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Generalization in Deep Networks: The Role of
Distance from Initialization</strong></span>,<br />
<em>Neural Information Processing Systems (NeurIPS) 2017 - Deep Learning: Bridging Theory and Practice</em><br />
Vaishnavh Nagarajan and J. Zico Kolter.<br />
<span style="background-color: #ffce00"><strong>Accepted for Spotlight talk</strong></span> <br />
<a href="https://arxiv.org/abs/1901.01672">[arxiv]</a> 
 <a href="../talks/dltp_poster.pdf">[Poster]
</a></li>
</ul>

<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>A Reinforcement Learning Approach to Online Learning of Decision Trees</strong></span>,<br />
<em>European Workshop on Reinforcement Learning (EWRL 2015 - ICML)</em> <br />
(Triple 1st author) Abhinav Garlapati, Aditi Raghunathan, Vaishnavh Nagarajan and Balaraman Ravindran.<br />
<a href="https://arxiv.org/abs/1507.06923">[arxiv]</a></li>
</ul>

<p style="margin:5px;"></p>

<ul>
  <li><span style="color:#c25c0a"><strong>Knows-What-It-Knows Inverse Reinforcement Learning</strong></span>,<br />
<em>Multidisciplinary Conference on Reinforcement Learning and Decision Making (RLDM) 2015</em><br />
Vaishnavh Nagarajan and Balaraman Ravindran<br />
<a href="../papers/rldm15.pdf">[PDF]</a></li>
</ul>

<p><br /></p>

<h3 id="thesis">Thesis</h3>

<ul>
  <li><span style="color:#c25c0a"><strong>Explaining generalization in deep learning: progress and fundamental limits</strong></span>,<br />
Vaishnavh Nagarajan<br />
<a href="https://arxiv.org/abs/2110.08922 ">[arxiv]</a></li>
</ul>

<hr />

<h2 id="peer-review">Peer Review</h2>

<ul>
  <li>ICLR 2021  (<span style="background-color: #ffce00"><strong>outstanding reviewer award</strong></span>)</li>
  <li>NeurIPS 2020 <span style="background-color: #ffce00"><strong>(top 10%)</strong></span>, 2019 <strong>(top 50%)</strong>, 2018 <strong>(top 30%)</strong></li>
  <li>ICML 2022, 2021 (Expert reviewier, <span style="background-color: #ffce00"><strong>top 10%</strong></span>), 2020 <strong>(top 33%)</strong>, 2019 <span style="background-color: #ffce00"><strong>(top 5%)</strong></span></li>
  <li>ALT 2021</li>
  <li>COLT 2019</li>
  <li>AISTATS 2019</li>
  <li>ICML 21 OPPO Workshop</li>
  <li>JMLR</li>
</ul>

<hr />

<p>Last Updated: Nov 16th, 2021</p>


          </section>
        </div>
    </div>
    <footer>

  <br />
  <script type="text/javascript" language="javascript">
  <!--
  // Email obfuscator script 2.1 by Tim Williams, University of Arizona
  // Random encryption key feature by Andrew Moulden, Site Engineering Ltd
  // This code is freeware provided these four comment lines remain intact
  // A wizard to generate this code is at http://www.jottings.com/obfuscator/
  //-->
  </script><noscript>My first name AT cs DOT cmu DOT edu</noscript>

					<br />
					<br />
  Built with Jekyll using Scribble.
  <br>
  <img src="../images/scribble2.png" alt="scribble" /> 
</footer>
  </body>
</html>