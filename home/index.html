<html>
  <head>
    <meta content=' - Vaishnavh Nagarajan' name='title' />
    <meta content=' - Vaishnavh Nagarajan' name='og:title' />
    <title>Vaishnavh Nagarajan</title>
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-55182625-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-55182625-3');
</script>



<link href='https://fonts.googleapis.com/css?family=IM Fell DW Pica|IM Fell DW Pica SC|IM Fell English|IM Fell English SC|IM Fell French Canon|IM Fell Great Primer|IM Fell Great Primer IT' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Garamond|EB Garamond' rel='stylesheet'>

<!--<link href='http://fonts.googleapis.com/css?family=Teko|Dosis:400,800|Economica|Josefin+Sans|Oswald|Indie+Flower|Pacifico|Roboto' rel='stylesheet' type='text/css'><link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css' /> -->
<link href='/stylesheets/style.css' rel='stylesheet' type='text/css' />
<link href='/stylesheets/syntax.css' rel='stylesheet' type='text/css' />
<link href='/stylesheets/responsive.css' rel='stylesheet' type='text/css' />
<!-- - -->
<script src='/javascripts/jquery.js' type='text/javascript'></script>
<script src='/javascripts/pd.js' type='text/javascript'></script>
<script src='/javascripts/basics.js' type='text/javascript'></script>
<script type="text/javascript" src="https://www.google.com/jsapi"></script>
<!-- - -->
<meta content='width=device-width, initial-scale=1.0, user-scalable=no' name='viewport'>
<meta content='text/html; charset=utf-8' http-equiv='content-type' />
<meta content="http://muan.co/images/og.png" property="og:image" />
<meta content="" property="fb:app_id" />

  <meta content='https://vaishnavh.github.io/' property='og:url' />
  <meta content="Welcome to my personal website!" property='og:description' />
  <meta content="blog" property="og:type" />

<!-- - -->


<!--
<script type='text/javascript'>
  //<![CDATA[
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', '']);
    _gaq.push(['_trackPageview']);
    
    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  //]]>
</script>
-->



<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TZ1W6KRGW0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-TZ1W6KRGW0');
</script>

<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1&appId=604714799556697";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>


<!-- for mathjax support -->



<!-- for mathjax support -->



  </head>
  <body>
    <header>
<!--<br><p>Vaishnavh Nagarajan</p>-->
</header>
    <div id='container'>
      <div class="content">
            <nav>

  <div class="navigation">
    <div class="logo"><a href="https://vaishnavh.github.io//home/index.html">Vaishnavh Nagarajan</a></div>
    <div class="menu">
  
    <a href="https://vaishnavh.github.io//home/index.html"  class="link">
      <div class="title">
      About
    </div>
    </a>
  
    <a href="https://vaishnavh.github.io//home/index.html#research"  class="link">
      <div class="title">
      Research
    </div>
    </a>
  
    <a href="https://vaishnavh.github.io//blog/index.html"  class="link">
      <div class="title">
      Blog
    </div>
    </a>
  
    </div>
  </div>
</nav>
          <section class='post'>
            <h1></h1>
            <img src="images/me.jpeg" height=50% style="padding: 20px 40px 40px 60px;" align="right"></img>

<!--<p style="font-family: Futura; font-weight:500; font-size:25">VAISHNAVH NAGARAJAN</p>-->
<!--<span style="font-family: 'Playfair Display'; font-weight:bold; font-size:30">About Me</span>-->

<p><span class="papertitle">
Research Scientist<br />
Google, New York<br />
E-Mail: vaishnavh at google.com<br />
<i>He/Him/His</i>
</span></p>

<p><a href="VaishnavhNagarajanResume.pdf"><b>Resume</b></a> | <a href="https://scholar.google.com/citations?hl=en&user=LrsjJfwAAAAJ&view_op=list_works&sortby=pubdate"><b>Google Scholar</b></a></p>

<p><a href="https://twitter.com/_vaishnavh?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @_vaishnavh</a><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p>I am a research scientist working in the foundations of AI. 
I graduated with a PhD from the Computer Science Department of Carnegie Mellon University (CMU) advised by <a href="http://zicokolter.com">Zico Kolter</a>. 
I completed my undergraduate studies in <a href="http://www.cse.iitm.ac.in/">the Department of Computer Science and Engineering</a> at IIT Madras, where I was advised by <a href="http://www.cse.iitm.ac.in/~ravi/">Balaraman Ravindran</a>.</p>

<div class="subheading">Research Interests</div>

<p>I like thinking about when and why complex AI systems work, in a way that brings theory and practice closer together. I am currently interested in understanding the limits of (and going beyond) the next-token prediction paradigm that underlies many current AI models (see <a href="https://arxiv.org/abs/2403.06963">this</a> recent work). My prior works similarly identify examples of failure (and occasionally, success!) across a broad range of settings in AI (typically what were prevailing paradigms back then). This includes out-of-distribution generalization, uniform-convergence-based generalization bounds and GAN optimization.</p>

<p><span style="font-size:12">Footnote: The process of “bringing theory and practice closer” is a fairly subjective balancing act. My own emphasis is on devising minimal (counter)examples that capture the core phenomena we empirically observe, and then formally reasoning about it. Such pared-down examples lead to simpler proofs and are therefore a powerful tool to gaining intution about growingly complex AI systems. Part of the insight we derive from this style lies in the simple proof; but importantly, part of it also lies in the assumptions and in a thoughtful design of the minimal system.</span></p>

<hr />

<div class="subheading">Updates</div>

<ul>
  <li>Jan 2024: ICML <a href="https://arxiv.org/abs/2403.06963">paper</a> with <a href="https://scholar.google.com/citations?user=bbGqqloAAAAJ&amp;hl=en">Gregor Bachmann</a> solidifying the debate on  next-token prediction.</li>
  <li>Oct 2023: <a href="https://arxiv.org/abs/2310.02226">Paper</a> with <a href="https://saching007.github.io/">Sachin Goyal</a> and collaborators at Google, exploring a simple change that introduces delays to how Transformers predict the next token.</li>
</ul>

<hr />

<div class="subheading">Students I have worked with</div>

<p>I have had the fortune of closely working with and/or mentoring the following students:</p>

<ul>
  <li><a href="https://scholar.google.com/citations?user=bbGqqloAAAAJ&amp;hl=en">Gregor Bachmann</a> (PhD student at ETH Zürich)</li>
  <li><a href="https://saching007.github.io/">Sachin Goyal</a> (PhD student at CMU, interned at Google, hosted by me)</li>
  <li><a href="https://sprin.xyz/">Jacob Springer</a> (PhD student at CMU)</li>
  <li><a href="https://scholar.google.com/citations?user=ddEToOoAAAAJ&amp;hl=en">Yuri Galindo</a> (mentee through <a href="https://www.fatimafellowship.com/mentors/past-mentors">Fatima Fellowship</a>)</li>
  <li><a href="://www.linkedin.com/in/marcus-blake-80b752251/">Marcus Blake</a> (Software Engineer at Google, mentee through <a href="https://let-all.com/">Learning Theory Alliance</a>)</li>
  <li><a href="https://healthyml.org/author/kimia-hamidieh/">Kimia Hamidieh</a> (now PhD student at MIT)</li>
  <li><a href="https://nuredinali.github.io/home/index.html">Nuredin Ali</a> (now PhD student at the Universiy of Minnesota)</li>
  <li><a href="https://thaonguyen19.github.io/">Thao Nguyen</a> (now PhD student at UW)</li>
  <li><a href="https://yidingjiang.github.io/">Yiding Jiang </a> (PhD student at CMU)</li>
  <li><a href="https://melroderick.github.io/">Melrose Roderick</a>  (now postdoc at Mila)</li>
  <li><a href="https://0-scholar-google-com.brum.beds.ac.uk/citations?user=JDS2BnIAAAAJ&amp;hl=sv">Jeffrey Li</a> (now PhD student at UW)</li>
</ul>

<hr />

<p><a id="research"></a></p>

<div class="subheading">Select Papers <a href="https://scholar.google.com/citations?hl=en&amp;user=LrsjJfwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">(Google Scholar)</a></div>

<p><br /></p>

<div class="subsubheading">CONFERENCE PUBLICATIONS</div>

<ul>
  <li><span class="papertitle">The pitfalls of next-token prediction</span>,<br />
<em>International Conference on Machine Learning (ICML) 2024</em>,<br />
(Double first author) Gregor Bachmann* and Vaishnavh Nagarajan*<br />
<a href="https://arxiv.org/abs/2110.08922 ">[arxiv]</a>
    <ul>
      <li>Also accepted for <span class="myhighlight">oral presentation</span> at ICLR ‘24 Workshop “How Far Are We From AGI?”</li>
    </ul>
  </li>
</ul>
<p style="margin:5px;"></p>

<ul>
  <li><span class="papertitle">Think before you speak: Training language models with pause tokens</span>,<br />
<em>International Conference on Learning Representations (ICLR) 2024</em>,<br />
Sachin Goyal, Ziwei Ji, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar, Vaishnavh Nagarajan<br />
<a href="https://arxiv.org/abs/2310.02226">[arxiv]</a>
<a href="talks/pause-poster.png">[Poster]</a>
    <ul>
      <li>Also accepted at NeurIPS ‘23 Workshop R0-FoMo: Robustness of Few-shot and Zero-shot Learning in Foundation Models</li>
    </ul>
  </li>
</ul>
<p style="margin:5px;"></p>

<ul>
  <li><span class="papertitle">Assessing Generalization via Disagreement</span>,<br />
<em>International Conference on Learning Representations (ICLR) 2022</em>,<br />
(Double first author) Yiding Jiang*, Vaishnavh Nagarajan*, Christina Baek, J. Zico Kolter<br />
<span class="myhighlight">Accepted for Spotlight presentation</span>      <br />
<a href="https://arxiv.org/abs/2106.13799">[arxiv]</a>
<a href="talks/GDE_poster.pdf">[Poster]</a>
    <ul>
      <li>Also accepted at ICML ‘21 Workshop on Overparameterization: Pitfalls &amp; Opportunities</li>
    </ul>
  </li>
</ul>
<p style="margin:5px;"></p>

<ul>
  <li><span class="papertitle">Understanding the failure modes of out-of-distribution generalization</span>,<br />
<em>International Conference on Learning Representations (ICLR) 2021</em>,  <br />
Vaishnavh Nagarajan, Anders Andreassen and Behnam Neyshabur<br />
<a href="https://arxiv.org/abs/2010.15775">[arxiv]</a>
<a href="talks/ood_poster.pdf">[Poster]</a>
    <ul>
      <li><strong>Invited</strong> poster presentation at <em>Conceptual Understanding of Deep Learning Workshop</em>, Google Algorithms Workshop Series, 2021.</li>
    </ul>
  </li>
</ul>
<p style="margin:5px;"></p>

<!--
- <span class="papertitle">A Learning Theoretic Perspective on Local Explainability</span>,    
_International Conference on Learning Representations (ICLR) 2021_,    
(Double first author) Jeffrey Li\*, Vaishnavh Nagarajan\*, Gregory Plumb and Ameet Talwalkar  
<a href="https://arxiv.org/abs/2011.01205">[arxiv]</a>
<a href="talks/interpretability_theory_poster.pdf">[Poster]</a>

<p style="margin:5px;"></p>
-->

<!--
- <span class="papertitle">Provably Safe PAC-MDP exploration using analogies</span>,  
_International Conference on
Artificial Intelligence and Statistics (AISTATS) 2021_  
Melrose Roderick, Vaishnavh Nagarajan and J. Zico Kolter   
<a href="https://arxiv.org/abs/2007.03574">[arxiv]</a>  
-->

<ul>
  <li><span class="papertitle">Uniform convergence may be unable to explain generalization in deep learning</span>,<br />
<em>Neural Information Processing Systems (NeurIPS) 2019</em><br />
Vaishnavh Nagarajan and J. Zico Kolter <br />
<span class="myhighlight">Winner of The Outstanding New Directions Paper Award</span><br />
<span class="myhighlight">Accepted for Oral presentation, 0.54% acceptance</span><br />
<a href="https://arxiv.org/abs/1902.04742">[arxiv]</a> 
 <a href="talks/neurips19_uc_slides.pdf">[NeurIPS 19 oral slides]</a>
 <a href="talks/neurips19_uc_poster.pdf">[Poster]</a>
 <a href="https://locuslab.github.io/2019-07-09-uniform-convergence/">[Blogpost]</a>
 <a href="https://github.com/locuslab/uniform-convergence-NeurIPS19">[Code]</a>
 <a href="errata/index.html#uc">[Errata]</a><br />
Also accepted for <span class="myhighlight">spotlight talk</span> at:
    <ul>
      <li><a href="https://sites.google.com/view/icml2019-generalization/home ">ICML ‘19 Workshop</a> on Understanding and Improving Generalization in Deep Learning</li>
      <li><a href="https://www.ias.edu/math/wtdl">IAS/Princeton Workshop</a> on Theory of Deep Learning. <a href="https://video.ias.edu/theorydeeplearning/2019/1016-Various">[Video]</a></li>
    </ul>
  </li>
</ul>

<p style="margin:5px;"></p>

<!-- - <span class="papertitle">Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience</span>,  
_International Conference of Learning Representations (ICLR) 2019_  
Vaishnavh Nagarajan and J. Zico Kolter   
<a href="https://openreview.net/forum?id=Hygn2o0qKX">[Openreview]</a> 
 <a href="https://s3.amazonaws.com/postersession.ai/0c93bed3-a55e-4c48-b3a8-bf47305cb2ef.jpg">[Poster]</a>
 <a href="errata/index.html#pac-bayes">[Errata]</a>
<p style="margin:5px;"></p> -->

<ul>
  <li><span class="papertitle">Gradient descent GAN optimization is locally stable</span>,<br />
<em>Neural Information Processing Systems (NeurIPS) 2017</em> <br />
Vaishnavh Nagarajan and J. Zico Kolter<br />
<span class="myhighlight">Accepted for Oral presentation, 1.2% acceptance</span> <br />
<a href="https://arxiv.org/abs/1706.04156">[arxiv]</a> <a href="talks/gan-stability-cmu.pdf">[1hr talk - slides]
</a> <a href="talks/nips17_oral.pdf">[NeurIPS Oral - Slides]
</a> <a href="talks/nips17_poster.pdf">[Poster]
</a> <a href="https://www.youtube.com/watch?v=9gQt6Vqb854">[3 min video]</a>
<a href="https://github.com/locuslab/gradient_regularized_gan">[Code]</a></li>
</ul>
<p style="margin:5px;"></p>

<!--
- <span class="papertitle">Lifelong Learning in Costly Feature Spaces</span>,  
_Algorithmic Learning Theory (ALT) 2017_  
with Maria-Florina Balcan and Avrim Blum  
Also an **invited** journal publication in Theoretical Computer Science (TCS)  
 <a href="https://arxiv.org/abs/1706.10271">[arxiv]</a><a href="talks/alt2017_talk.pdf">[Slides]</a> 
 <p style="margin:5px;"></p>
-->

<!--
- <span class="papertitle">Learning-Theoretic Foundations of Algorithm Configuration for Combinatorial Partitioning Problems</span>,  
_Conference On Learning Theory (COLT), 2017_  
with Maria-Florina Balcan, Ellen Vitercik and Colin White  
<a href="https://arxiv.org/abs/1611.04535">[arxiv]</a>
<a href="talks/simons-talk.pdf">[Slides]</a>
<a href="https://www.youtube.com/watch?v=9O1Tc2pp0E0">[Talk]</a>
<p style="margin:5px;"></p>
-->

<!--
- <span class="papertitle">Every team deserves a second chance: Identifying when things go wrong</span>,  
_Autonomous Agents and Multiagent Systems (AAMAS) 2015_  
(Double 1st author) Vaishnavh Nagarajan\*, Leandro S. Marcolino\* and Milind Tambe   
<a href="/papers/aamas15.pdf">[PDF]</a>   <a href="/papers/aamas15-ap.pdf">[Appendix]</a>
-->

<p><br /></p>

<div class="subsubheading">WORKSHOP PAPERS</div>

<ul>
  <li><span class="papertitle">Theoretical Insights into Memorization in GANs</span>,<br />
<em>Neural Information Processing Systems (NeurIPS) 2017 - Integration of Deep Learning Theories Workshop</em><br />
Vaishnavh Nagarajan, Colin Raffel, Ian Goodfellow.<br />
<a href="papers/GAN_memorization.pdf">[PDF]</a></li>
</ul>

<p style="margin:5px;"></p>

<ul>
  <li><span class="papertitle">Generalization in Deep Networks: The Role of
Distance from Initialization</span>,<br />
<em>Neural Information Processing Systems (NeurIPS) 2017 - Deep Learning: Bridging Theory and Practice</em><br />
Vaishnavh Nagarajan and J. Zico Kolter.<br />
<span class="myhighlight">Accepted for Spotlight talk</span> <br />
<a href="https://arxiv.org/abs/1901.01672">[arxiv]</a> 
 <a href="talks/dltp_poster.pdf">[Poster]
</a></li>
</ul>

<p style="margin:5px;"></p>

<!--
- <span class="papertitle">A Reinforcement Learning Approach to Online Learning of Decision Trees</span>,  
_European Workshop on Reinforcement Learning (EWRL 2015 - ICML)_   
(Triple 1st author) Abhinav Garlapati, Aditi Raghunathan, Vaishnavh Nagarajan and Balaraman Ravindran.  
<a href="https://arxiv.org/abs/1507.06923">[arxiv]</a>  
<p style="margin:5px;"></p>


- <span class="papertitle">Knows-What-It-Knows Inverse Reinforcement Learning</span>,  
_Multidisciplinary Conference on Reinforcement Learning and Decision Making (RLDM) 2015_  
Vaishnavh Nagarajan and Balaraman Ravindran  
<a href="/papers/rldm15.pdf">[PDF]</a> 
-->

<p><br /></p>

<div class="subsubheading">THESIS</div>

<ul>
  <li><span class="papertitle">Explaining generalization in deep learning: progress and fundamental limits</span>,<br />
Vaishnavh Nagarajan, 2021<br />
<a href="https://arxiv.org/abs/2110.08922 ">[arxiv]</a></li>
</ul>

<p><br /></p>

<hr />

<div class="subheading">Peer Review</div>

<ul>
  <li>ICLR 2023, 2021  (<span class="myhighlight">outstanding reviewer award</span>)</li>
  <li>NeurIPS 2023, 2021, 2020 <span class="myhighlight">(top 10%)</span>, 2019 <strong>(top 50%)</strong>, 2018 <strong>(top 30%)</strong></li>
  <li>ICML 2024 &amp; 2023 (Expert reviewer), 2022, 2021 (Expert reviewer, <span class="myhighlight">top 10%</span>), 2020 <strong>(top 33%)</strong>, 2019 <span class="myhighlight">(top 5%)</span></li>
  <li>COLT 2019</li>
  <li>ALT 2021</li>
  <li>UAI 2022</li>
  <li>AISTATS 2023 (top 10%) 2019</li>
  <li>JMLR, Nature</li>
  <li>Workshops: ICML 22 PODS, ICML 21 OPPO, ICLR-Me-FOMO 2023, DistShift NeurIPS 2023, R0-FoMo NeurIPS 2023 (area chair)</li>
</ul>

<hr />

<p>Last Updated: Apr 23th, 2024</p>


          </section>
        </div>
    </div>
    <footer>

  <br />
  <script type="text/javascript" language="javascript">
  <!--
  // Email obfuscator script 2.1 by Tim Williams, University of Arizona
  // Random encryption key feature by Andrew Moulden, Site Engineering Ltd
  // This code is freeware provided these four comment lines remain intact
  // A wizard to generate this code is at http://www.jottings.com/obfuscator/
  //-->
  </script><noscript>first name AT google DOT com</noscript>

					<br />
					<br />
  Built with Jekyll using Scribble.
  <br>
  <img src="https://vaishnavh.github.io//images/scribble2.png" alt="scribble" /> 
</footer>
  </body>
</html>