<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vaishnavh Nagarajan</title>
    <description>Welcome to my personal website!</description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>What does a language model model?</title>
        <description>&lt;p&gt;&lt;strong&gt;TL;DR: Does the next-token logit track the conditional or the joint probability of the whole sequence?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I had an invisible &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Invisible_Gorilla&quot;&gt;gorilla&lt;/a&gt; moment while reading a paper. Even though the paper interprets the gorilla in a way I’m not in agreement with, in helping me notice something so basic that was staring at me all along, the paper led me closer to clarity.&lt;/p&gt;

&lt;p&gt;The paper is called “Spilled Energy in Large Language Models” by &lt;a href=&quot;https://arxiv.org/abs/2602.18671&quot;&gt;Robert et al., 2026&lt;/a&gt;&lt;sup id=&quot;fnref:paper&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:paper&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; which proposes a way to predict whether or not a generated token is hallucinated. The proposal is simple and cute: when you generate a token, if you’re suspicious of it, take the corresponding logit of that token as $\tt{Term} 1$; feed the suspicious token in and proceed to the next step, where you take the &lt;em&gt;denominator&lt;/em&gt; of the softmax probability as $\tt{Term 2}$. If  $\tt{Term 2}$ is much smaller than $\tt{Term 1}$, your model has likely hallucinated. This difference quantity is what they call as “Spilled Energy”.&lt;/p&gt;

&lt;p&gt;Specifically, if $f( \tt{token} ; \tt{context} )$ is my language model’s logit on a token given a context as input, if $x$ is my suspicious token, and $y’$ some next token candidate (I’ll save the symbol $y$ for later!), then:&lt;/p&gt;

\[\begin{equation}
\textrm{Spilled Energy} = \underbrace{f(x ; \tt{context})}_{\tt{Term1}} - \underbrace{\log \sum_{y&apos;} \exp(f( y&apos; ; {\tt context}, x))}_{\tt{Term2}} 
\end{equation}\]

&lt;p&gt;&lt;img src=&quot;/assets/images/2026-02-27-joint-or-conditional/spilled_energy.jpg&quot; alt=&quot;SpilledEnergy&quot; class=&quot;theme-aware-img center-image&quot; style=&quot;width: 40%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First things first, I made sure this smelled good: ${\tt Term 1}$ reflects the enthusiasm&lt;sup id=&quot;fnref:enthusiasm&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:enthusiasm&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; of the model in predicting the suspicious token, ${\tt Term 2}$  the enthusiasm of the model in continuing that train of thought for one more step, summed over all possible continuations.  If the model abruptly turns unenthusiastic, it means that the model has found itself in a grave it enthusiastically dug one step ago. Makes sense. But is this handwavy justification all there is to it?&lt;/p&gt;

&lt;h3 id=&quot;the-papers-interpretation&quot;&gt;The paper’s interpretation&lt;/h3&gt;

&lt;p&gt;The paper offers a tighter justification. The joint probability that the model assigns to a sequence must be decomposible into next-token probabilities, a fact the reader should be able to blurt out in sleep:&lt;/p&gt;

\[\require{color}
\begin{align}
  p({\tt context}, x, y) &amp;amp; =  p({\tt context}) \cdot p(x | {\tt context}) \cdot p(y| {\tt context}, x) \\ 
  &amp;amp; = p({\tt context}) \cdot \frac{\colorbox{silver}{$\color{black} p({\tt context}, x )$}}{p({\tt  context})} \cdot \frac{p({\tt context}, x, y)}{\colorbox{silver}{$\color{black} p({\tt context}, x )$}} \label{eq:dec1}
\end{align}\]

&lt;p&gt;Then comes the main claim: we’ve designed the next-token-predicting language model to capture these very next-token quantities; which means ideally every numerator and its subsequent denominator, as estimated by the model, should cancel out (our ${\tt Term1}$ and ${\tt Term 2}$). &lt;em&gt;Yet, the claim goes, nothing in a language model imposes this constraint on its estimates!&lt;/em&gt; Specifically if we let $\hat{p}$ be the model’s assigned probability to a sequence, we can write it in a way (see Eq $\ref{eq:energy}$) that we can “superimpose” it against the above equation (Eq $\eqref{eq:dec1}$), to infer that ${\tt Term1}$ must match ${\tt Term2}$. When these Terms do not match in practice, we are to conclude that there is profoundly erratic behavior within the model, manifesting as hallucinations.&lt;/p&gt;

\[\begin{align}
  \hat{p}({\tt context}, x, y) &amp;amp; =  p({\tt context}) \cdot \frac{ 
  \overbrace{
  \colorbox{silver}{$\color{black}\exp{f(x; \tt{context})}$
  }}^{\propto \exp({\tt Term1})}}{\sum_{x&apos;} \exp{f(x&apos;; {\tt context})}} \cdot  \frac{ \exp{f(x; \tt{context})}}{\underbrace{
  \colorbox{silver}{$\color{black}\sum_{y&apos;} \exp{f(y&apos;; {\tt context}, x)}$}
  }_{\propto \exp(\tt Term2)}} \label{eq:energy} \\ 
\end{align}\]

&lt;h3 id=&quot;my-interpretation&quot;&gt;My interpretation&lt;/h3&gt;

&lt;p&gt;This disturbed me: how had I missed a gorilla hiding in an object I had stared at for weeks at one point?&lt;sup id=&quot;fnref:ntp&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:ntp&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;A further staring contest somewhat resolved this confusion: I had never done the superimposition this way (and I wouldn’t do it this way). I had always superimposed Eq $\eqref{eq:energy}$ over a decomposition different from Eq $\ref{eq:dec1}$:&lt;/p&gt;

\[\begin{align}
  p({\tt context}, x, y) 
  &amp;amp; = p({\tt context}) \cdot \frac{
  \colorbox{silver}{$\color{black}p({\tt context} | x )$}
  }{\sum_{x&apos;} p({x&apos; | \tt  context})} \cdot \frac{p(y | {\tt context}, x)}{
  \colorbox{silver}{$\color{black}\sum_{y&apos;} p(y&apos; | {\tt context}, x)$}
  }
   \label{eq:w}
\end{align}\]

&lt;p&gt;In other words, I had always viewed the logits as representing how likely the next-token was, rather than how likely the whole sequence was! In this expression, it is clear that the numerator and the denominator (which is always $1$) do not match. Here, $\tt{Term1}$ is proportional to the numerator, but the constant is &lt;em&gt;local&lt;/em&gt; to token $x$’s probability; likewise $\tt{Term2}$ is proportional to its denominator, with a constant local to $y$’s probability.&lt;/p&gt;

&lt;p&gt;To me this was the obvious interpretation: we train a model on the “next-token loss” with the hope that it learns how good/bad that token is, with no care for how likely the input sequence is.&lt;/p&gt;

&lt;h3 id=&quot;its-not-that-clear-which-interpretation-is-correct&quot;&gt;It’s not that clear which interpretation is correct.&lt;/h3&gt;

&lt;p&gt;But then, I realize that this interpretation—that the next-token prediction only models the next-token’s likelihood—is not as clear-cut. While the next-token loss indeed stipulates what the &lt;em&gt;probabilities&lt;/em&gt; must be—the next-token conditionals—the &lt;em&gt;logit&lt;/em&gt; magnitudes themselves are underdetermined. Usually, in gradient-descent-trained models, if something is free to move as it pleases, it moves gracefully, and we may find this grace in the logits too. On seen contexts, a well-trained generative model’s logits will be forced to spike up (to $\infty$) on the seen next-token and spike down (to $-\infty$) everywhere else and so the “total energy” in  ${\tt Term 2}$ would explode. On completely bizarre contexts (say, due to our suspicious $x$ token), the next-token logits are “free to be what they want” and so, we may expect them to largely remain unenthusiastic (blunting ${\tt Term 2}$). In between these extremes, as we get closer and closer to the training manifold, we can expect the logits to be more and more enthusiastic on some next-tokens. This way, it seems that the total energy term in ${\tt Term 2}$ is indeed indicative of the how likely the $({\tt context}, x, y)$ sequence is!&lt;/p&gt;

&lt;p&gt;It’s funny that this argument can be applied to even make boring image classifiers appear as though they are models of the input distribution:  when your input image is garbage, the logits are likely tiny in magnitude; when your input image is realistic, the logits are higher in magnitude.&lt;/p&gt;

&lt;p&gt;Now, I do not mean to say that these logits are exactly representative of the joint probability. On some reasonable inputs, the next-token logits may be unenthusiastic
purely due to poor learning resulting in lack of confidence on its next-token prediction. But what of a model that has perfectly learned the next-token conditionals?  Is its logits nicely representative of the joint distribution?&lt;/p&gt;

&lt;h3 id=&quot;the-question&quot;&gt;The question&lt;/h3&gt;

&lt;p&gt;My takeaway is this: surely, next-token probabilities of a model indeed only model the conditionals; but due to the implicit bias of gradient descent, it’s possible that the next-token logits reflect, to some extent, the joint probability of $({\tt context}, x)$, with some additional factors corresponding to the next-token confidence itself.  Is this just a feel-good empirical observation? Or is it possible to give this a mathematical form? Has someone already done this?&lt;/p&gt;

&lt;p&gt;Maybe this gorilla was always visible and many knew;  or maybe this gorilla is just in my imagination; but for the time being, I will enjoy the feeling of having noticed it.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Footnotes&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:paper&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Spilled Energy in Large Language Models, Adrian Robert Minut, Hazem Dewidar, Iacopo Masi, 2026, &lt;a href=&quot;https://arxiv.org/abs/2602.18671&quot;&gt;https://arxiv.org/abs/2602.18671&lt;/a&gt; &lt;a href=&quot;#fnref:paper&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:enthusiasm&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;I use “enthusiasm” to avoid using “confidence” which usually refers to a probability value between 0 and 1. &lt;a href=&quot;#fnref:enthusiasm&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ntp&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;I remember staring at it when setting up the notations for “the pitfalls of next-token prediction” &lt;a href=&quot;https://arxiv.org/abs/2403.06963&quot;&gt;paper&lt;/a&gt;, during which came the (obvious-sounding) realization that the next-token predicting backbone by itself does not define a joint distribution over a future sequence; it only defines the next-token distribution. It’s the autoregressive wrapper around it that defines the joint distribution; a different wrapper would yield a different joint! Sounds trivial, but disentangling this in our notation helped clean up our thoughts. &lt;a href=&quot;#fnref:ntp&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 27 Feb 2026 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/blog/joint-or-conditional/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/joint-or-conditional/</guid>
      </item>
    
      <item>
        <title>Angles between high-dimensional vectors</title>
        <description>&lt;p&gt;Switch off your brain and answer this:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Given three points $\mathbf{X}, \mathbf{Y}, \mathbf{Z}$ sampled from a high-dimensional zero-centered isotropic Gaussian $\mathcal{N}(0, \mathbf{\Sigma})$, roughly, what is the angle between the lines given by $\mathbf{A} = \mathbf{X} - \mathbf{Y}$ and $\mathbf{B} = \mathbf{Z} - \mathbf{Y}$?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2025-12-16-high-dimensional-diff/img1.jpg&quot; alt=&quot;The question&quot; class=&quot;theme-aware-img center-image img-rounded&quot; style=&quot;width: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you answered &lt;span class=&quot;spoiler&quot; onclick=&quot;this.classList.toggle(&apos;revealed&apos;)&quot; title=&quot;Click to reveal&quot;&gt;
  $90^\circ$
&lt;/span&gt;, that is not right. 
The right answer is in fact, a cute yet shocking&lt;span class=&quot;spoiler&quot; onclick=&quot;this.classList.toggle(&apos;revealed&apos;)&quot; title=&quot;Click to reveal&quot;&gt;
  $60^\circ$
&lt;/span&gt;.&lt;sup id=&quot;fnref:curvature&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:curvature&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;It’s entrenched in us that everything becomes funny in high-dimensions, and one such funny thing we know all too well is that &lt;em&gt;if you independently sample two vectors from a zero-centered, isotropic Gaussian, they must be at right angles&lt;/em&gt; (with high probability etc., etc.,). We sense that the two directions ($\mathbf{A}$ and $\mathbf{B}$) look just like two zero-centered, isotropic Gaussian directions—which they are—and by our funny law, they should be orthogonal to each other—which they are not!&lt;/p&gt;

&lt;p&gt;There is joy in trying to reconcile this from various angles; try it yourself before you read below. The process of reconciliation also generated some philosophical mumblings; I leave them at the end of the post.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;the-algebraic-reconciliation&quot;&gt;The algebraic reconciliation&lt;/h3&gt;

&lt;p&gt;For a blunt reconciliation, I go through the motions of computing the expected dot-product of $\mathbf{A} \cdot \mathbf{B}$ as below,&lt;/p&gt;

&lt;p&gt;\(\require{cancel} \mathbb{E}[ (\mathbf{X} - \mathbf{Y})\cdot (\mathbf{Z} - \mathbf{Y})] = \cancelto{0}{\mathbb{E}[\mathbf{X}\cdot\mathbf{Z}]} + \cancelto{0}{\mathbb{E}[\mathbf{Y}\cdot\mathbf{Z}]} + \cancelto{0}{\mathbb{E}[\mathbf{X}\cdot\mathbf{Y}]} + \underbrace{\mathbb{E}[\mathbf{Y}\cdot\mathbf{Y}]}_{&amp;gt; 0}\),&lt;/p&gt;

&lt;p&gt;and I find that things don’t cancel out to zero! Thus, the angle cannot concentrate around $90^\circ$. But I find this argument too robotic to be insightful.&lt;/p&gt;

&lt;h3 id=&quot;the-statistical-reconciliation&quot;&gt;The statistical reconciliation&lt;/h3&gt;

&lt;p&gt;Alternatively, I could say that my folly was in treating the two quantities, $\mathbf{A}$ and  $\mathbf{B}$ as two &lt;em&gt;independent&lt;/em&gt;  zero-centered Gaussian random variables. Zero-centered Gaussian they are, independent they are not: the presence of “$\mathbf{Y}$” in both terms spoils the relationship. Knowing $\mathbf{A}$ i.e., $\mathbf{X}-\mathbf{Y}$ gives me an updated belief over  where $\mathbf{Z} - \mathbf{Y}$ i.e., $\mathbf{B}$ could be.
 Therefore, I can’t cite the funny law of high-dimensional-orthogonality here.&lt;/p&gt;

&lt;p&gt;But I find this argument too bureaucratic to be insightful. (“You broke this precondition, so this claim cannot be processed.” Why, thank you, insurance agent!)&lt;/p&gt;

&lt;h3 id=&quot;the-other-statistical-reconciliation&quot;&gt;The other statistical reconciliation&lt;/h3&gt;

&lt;p&gt;Let me freeze $\mathbf{Y}$ at some specific value $\mathbf{y}$. &lt;em&gt;Conditioned&lt;/em&gt; on $\mathbf{Y}=\mathbf{y}$, I think about what the angle between $\mathbf{X}-\mathbf{y}$ and $\mathbf{Z}-\mathbf{y}$ concentrates towards. Under this conditioning, I see that although these variables are independent, they are &lt;em&gt;no longer&lt;/em&gt; zero-centered Gaussian: they have mean $\mathbf{y}$. Once again, I am mysteriously blocked from citing the funny high-dimensional law, this time by a different force.&lt;/p&gt;

&lt;h3 id=&quot;the-frame-of-reference-reconciliation&quot;&gt;The frame-of-reference reconciliation&lt;/h3&gt;

&lt;p&gt;Both the above statistical arguments can in fact be expressed more vividly. What I did right above was to move my frame of reference to the “$\mathbf{y}$”. By relabeling “$\mathbf{y}$” as my new origin $\mathbf{O}’$ (see image below), what were once the points $\mathbf{X}$ and $\mathbf{Z}$, are now points $\mathbf{A}$ and $\mathbf{B}$. These points are sampled from a far-off Gaussian galaxy that is centered at $-\mathbf{y}$; not centered around me! So, from my planet at $\mathbf{y}$, the directions $\mathbf{A}$ and $\mathbf{B}$ appear in the sky roughly
in the direction of that galaxy; not at right angles.&lt;sup id=&quot;fnref:milkyway&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:milkyway&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 
In this universe, you can also “see” how knowing where $\mathbf{A}$ is, gives you an updated belief over where $\mathbf{B}$ is.&lt;/p&gt;

&lt;p&gt;In hindsight, this is also what the “algebraic reconciliation” was trying to tell me when it spat out $\mathbb{E}[(-\mathbf{Y}) \cdot (-\mathbf{Y})]$ as the dot-product $\mathbb{E}[\mathbf{A} \cdot \mathbf{B}]$. Sadly, this is robotic garble I couldn’t parse then.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2025-12-16-high-dimensional-diff/img2.jpg&quot; alt=&quot;Frame-of-reference reconciliation&quot; class=&quot;theme-aware-img center-image&quot; style=&quot;width: 60%;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-geometric-reconciliation&quot;&gt;The geometric reconciliation&lt;/h3&gt;

&lt;p&gt;Now, there’s one more elegant visualization. We can legally cite a different funny law in high-dimensions: the distances between two random points from a Gaussian concentrate around a fixed value. This value doesn’t matter. All that matters is that this is true of the distances between every pair of $\mathbf{X}, \mathbf{Y} \; \&amp;amp; \; \mathbf{Z}$, which means  these points together form a delightful equilateral triangle. QED.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2025-12-16-high-dimensional-diff/img3.jpg&quot; alt=&quot;Geometric reconciliation&quot; class=&quot;theme-aware-img center-image&quot; style=&quot;width: 30%;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;philosophical-notes&quot;&gt;Philosophical Notes&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;When our gut feeling says that the angle was $90^\circ$, were we tricked by the deceptive nature of high-dimensions, or were we tricked by something more rudimentary? (I think it’s the latter.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;When we learn a new thing,
    &lt;ul&gt;
      &lt;li&gt;we examine the thing from various angles&lt;/li&gt;
      &lt;li&gt;we examine every existing intuition in our head that is at odds with the thing&lt;/li&gt;
      &lt;li&gt;and we work until all possible contradictions are reconciled;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;only then does the thing become a part of our world view without resistance; only then do we feel like we understood the thing to completion.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It’s a useful exercise to “shut one’s brain” and see where it goes right or wrong. Don’t think step by step.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I don’t feel like I learned something satisfyingly without the aid of visualizations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How much of AI model training reflects the above two human ways of incorporating new knowledge?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;What does it really mean to explain something?&lt;/em&gt; The algebraic reconciliation explains little. It is somewhat analogous to proving a generalization guarantee for a deep network with a 100-page step-by-step analysis of each layer when trained on a Gaussian distribution — does it really explain generalization of overparameterized models? In the 1970s, when Appel and Haken gave their computer-aided proof for the four-color theorem, there was criticism from mathematicians. It was not aesthetic; the computer-generated part of the proof allegedly was a “four-foot-high computer printout”; one couldn’t glean high-level arguments or insights into the “why” behind the truth; in fact, one couldn’t even verify and convince themselves of the truth without spending astronomical amounts of time. Jim Holt writes about this in a beautiful essay, &lt;a href=&quot;https://www.nybooks.com/articles/2003/05/29/a-comedy-of-colors/&quot;&gt;“A Comedy of Colors”&lt;/a&gt;, asking what makes a proof a proof.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes:&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:curvature&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;The question arose thanks to Eghbal who was discussing his experiments in this &lt;a href=&quot;https://arxiv.org/abs/2311.04930&quot;&gt;paper&lt;/a&gt;, examining how the internal state of a Transformer evolves over time. If you replace $\mathbf{X}, \mathbf{Y}, \mathbf{Z}$ with the representation $\mathbf{R}_t$ at three consecutive timesteps, you can then ask how the angle $\mathbf{R}_{t+1}-\mathbf{R}_t$ and $\mathbf{R}_{t+2} -\mathbf{R}_{t+1}$ evolves over time. In their experiments, you’ll see that their baseline angle (e.g., the angle at the start) is $120^\circ$ and not $90^\circ$. &lt;a href=&quot;#fnref:curvature&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:milkyway&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;The strange thing is that we are also literally their of this galaxy! It’s almost like how Earthlings can look at their home galaxy (the Milky Way) while being at the edge of it. However, unlike the Milky Way, a Gaussian galaxy is not a flat spiral, but a thin shell. &lt;a href=&quot;#fnref:milkyway&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 16 Dec 2025 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/blog/high-dimensional-diff/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/high-dimensional-diff/</guid>
      </item>
    
      <item>
        <title>Research philosophy</title>
        <description>&lt;hr /&gt;

&lt;p&gt;In this post, I pompously share my thoughts on how I aspire to be a researcher. My hope is that junior researchers who hold similar ideas and have faced the challenges that come with holding them, feel some sense of support from reading this. I’m always happy to chat more about navigating these challenges amidst the rat race that is AI/ML research.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;I seek simple, insightful results unburdened by mathematical obfuscation. This means pursuing minimal abstractions, example and counterexamples, vivid intuition, clarity and depth of thought and nuanced argumentation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Researchers should be publishing significantly less. In the first ten years of my career (2015 to 2025, the date I write this) I have published about a paper a year&lt;sup id=&quot;fnref:author&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:author&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;,  I wish it was less frequent.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Peer review is a form of taxation. If you publish more, you should review more, while ensuring that your reviews are of high quality. The System Is Broken™ in part because everyone’s publishing more without paying their fair share of taxes (and also because there’s more of everyone).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I care about clear and accessible communication. I enjoy spending an unhealthy amount of time on making my &lt;a href=&quot;/talks&quot;&gt;talks&lt;/a&gt; and writing my papers. This is a constant learning process—every paper or talk takes at least two or three attempts to attain clear presentation. There is significant insight to be  derived from this process.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I enjoy the detective work that goes behind cataloging an extensive, well-organized related work section. It’s a satisfying process. If there are missing citations in my work, please reach out to me so I can rectify it. Again, there is significant insight (and knowledge) to be derived from this process!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I  believe that science must be done and truth must be sought collaboratively with compassion and good faith, building on each other’s works and strengths.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Science is more subjective than it is made out to be. We must embrace this with humility. It’s not always obvious what questions are important, or what directions will be fruitful.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;At this point in my field, the only form of external validation that matters to me is when others tangibly build on my work, or if someone enjoyed reading my work. All other metrics (including citations, publications, awards, talk invitations and fellowships I’ve listed elsewhere on this site) have become utterly meaningless.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Byte-sized dissemination of research on twitter has been a terrible idea for science (but I do it anyway). It has encouraged reductive and combative interactions. &lt;sup id=&quot;fnref:1:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;My values are shaped by what I’ve &lt;a href=&quot;/blog/history-of-science/&quot;&gt;read&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Footnotes&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:author&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;As lead contributor or mentor. As I grew in seniority, I’ve additionally participated as a “middle author” in about a paper a year. &lt;a href=&quot;#fnref:author&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Yes, that’s hypocritical! But also see the &lt;a href=&quot;https://en.wikipedia.org/wiki/Tu_quoque&quot;&gt;Tu quoque&lt;/a&gt; fallacy. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:1:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 05 Dec 2025 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/blog/research-philosophy/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/research-philosophy/</guid>
      </item>
    
      <item>
        <title>Why PhD students should read the history of science</title>
        <description>&lt;p&gt;Here’s a secret I accidentally discovered during my PhD: consuming history-of-science content is a powerful way to nurture your emotional maturity as a researcher.&lt;/p&gt;

&lt;p&gt;You’ll notice, even as you read two random pages from the history of science, the pages have an uncanny resemblance to each other, and to the one you’re writing! Every tale of discovery demonstrates that:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Scientists always gambled in the scientific process, and made mistakes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Science is noisy and subjective. There can be great subjectivity in interpreting a result or appreciating the significance of a direction. The subjectivity may disappear only in hindsight with more data and more exploration. Many discoveries that are now canonical, were disputed in their infancy.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lesser-known scientists were rarely taken seriously, especially by scientists who were backed by reputation or seniority or systemic power or mere confidence. There were always pushbacks, humiliations, and complete indifference.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Controversies between scientists has always been the norm. “Big and proud” personalities in power have made other scientists’ lives miserable. Or at times, two “big” scientists on an equal footing sparred publicly with each other. It wasn’t very nice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Credit assignment has always been noisy and at other times, deliberately unfair. Some great scientific discoveries were tragically known only long after their originator’s passing.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;There are important lessons in these observations&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; that make you a more level-headed and emotionally mature researcher.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;You learn to&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;recognize the inevitable ups and downs of the research process,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;navigate the terrain of research with grit,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;value deeply satisfying long-term ambitions over anxiety-inducing short-term goals,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;value goal-less, curiosity-driven random explorations as an exciting and important part of working at the frontier of human knowledge,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;not perceive certain setbacks or the lack of external validation as a personal attack in those situations where it is not personal but pure noise (not always the case!),&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;not be intimidated by those who may assert their subjective opinions as objective truth with authority (this is my favorite lesson),&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hold on to a measured conviction in your own opinions (second favorite lesson).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some of these lessons&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; may sound like platitudes; but learning how these have repeatedly manifested in history — through vivid narrative detail — leaves a profound imprint on how you operate as a researcher, and how you construct an inner narrative about your role in the scientific community.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;I contend that you cannot learn this emotional maturity efficiently through the brute-force of the research process alone. You need to read.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reading-list&quot;&gt;Reading list&lt;/h3&gt;

&lt;p&gt;Here are some of the books I would recommend. I’ll continue to update this over time. &lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Longitude&lt;/strong&gt; by Dava Sobel&lt;/summary&gt;
  &lt;p&gt;This little book describes the story of how 18th century governments and monarchies funded a race to design the clock, a race that stemmed from colonial ambitions (you need clocks to track the longitude which until then was extremely cumbersome and prone to ship-wrecking errors). The book covers the competition and drama that ensued between inventors and powerful astronomers and the magnitude of grit that was involved in the inventor&apos;s process.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Chaos: Making a New Science&lt;/strong&gt; by James Gleick&lt;/summary&gt;
  &lt;p&gt;This narrates the emergence of Chaos Theory as a standalone discipline (born from problems and observations in various other disciplines) and the pushbacks it experienced along the way. The book also describes the basic tenets of chaos theory in a way that is easy to follow.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Chasing Venus: The Race to Measure the Heavens&lt;/strong&gt; by Andrea Wulf&lt;/summary&gt;
  &lt;p&gt;This thriller-like (true) story tracks the journey of a dozen astronomers (of many) in the 1760s as they raced to colonies in various corners of the globe. Their goal was to time the journey of the Venus across the Sun in a bid to measure the distance of the Sun from the Earth. The scientists and astronomers worked across imperial borders to consolidate resources and collaborate (or not!), and in their race against time, they faced one obstacle after another, political, logistical and meteorological. Many failed. The book details the competition that developed between various astronomers (and like Longitude, also how all of this was deeply tied to colonization).&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Great Feuds in Science: Ten of the Liveliest Disputes Ever&lt;/strong&gt; by Hal Hellman&lt;/summary&gt;
  &lt;p&gt;This outlines instances across the vast history of science where two ideas or two people collided head-on. Some of these you may already be aware of, like the one between Newton and Leibniz or the one between Galileo and the Pope. But the book digs out little historical details which paint a picture of many of these debates nastier than what you’d have imagined.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;When Einstein Walked with Gödel&lt;/strong&gt; by Jim Holt&lt;/summary&gt;
  &lt;p&gt;A collection of essays on science and mathematics, each with a unique insight into some of the lessons I brought up earlier.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;The Golem&lt;/strong&gt; by Collins and Pinch&lt;/summary&gt;
&lt;p&gt;Written by sociologists, this is a collection of case studies illustrating how science is messier than we think it, how experimental results, at the time of a discovery of a result, were not as conclusive as they seem many years later and how there can be much controversy over interpreting an observation. The book was a fun read! The chapter on the Pasteur-Pouchet debates (about spontaneous generation of life) was my favorite.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Accidental Astronomy: How Random Discoveries Shape the Science of Space&lt;/strong&gt; by Chris Lintott&lt;/summary&gt;
  &lt;p&gt;This describes the serendipitous history leading up to many astronomical discoveries. The story of how radio astronomy came to be is absolutely fascinating. The book also led me to learning about the story of Jocelyn Bell who discovered the  pulsars but was &lt;a href=&quot;https://www.sciencenews.org/article/jocelyn-bell-burnell-physics-prize-pulsar-discovery-interview&quot;&gt;not awarded&lt;/a&gt; the Nobel Prize.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;The Creative Moment&lt;/strong&gt; by Joseph Schwartz&lt;/summary&gt;
  &lt;p&gt; A collection of (provocative) essays describing how various scientific discoveries were triggered by a political or social force; and also, how the natural sciences became more and more abstract and obscured in the public eye (beginning at the moment Galileo mathematized physics when in conflict with the Church), and how the ways of doing science have transformed from lone inventors to large highly-managed teams, a fact that is true of machine learning and AI too.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Inventing Temperature&lt;/strong&gt; by Hasok Chang&lt;/summary&gt;
  &lt;p&gt;This narrates the long history behind how temperature began to measured like how it is right now. There are details about the physics of it (some of it was a bit dense for a casual read for me), but also details about the disputes and confusion that transpired along the way.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;There are places in the world where rules are less important than kindness&lt;/strong&gt; by Carlo Rovelli&lt;/summary&gt;
  &lt;p&gt;A collection of essays by a theoretical physicist that touches upon many things broadly: science, anthropology, also of the life of a young scientist, and of many other social and human values.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;A Sense of the Mysterious&lt;/strong&gt; by Alan Lightman&lt;/summary&gt;
  &lt;p&gt; The essays here describe the emotional experience of a scientist and the intersection of being scientist and an artist (Alan’s writing about this is beautiful; it deeply resonated with me) and the power of metaphors in scientific thinking. There are also insightful historical accounts of some scientists and discoveries; my favorite is the essay titled “Megaton Man” which descibes the personality of Edward Teller who was involved in the Manhattan Project.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Science and Government&lt;/strong&gt; by CP Snow&lt;/summary&gt;
  &lt;p&gt; A long essay (or a short book?) that narrates the rivalry between two scientists who were at the helm of British military technology during the second World War.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Indiscrete Thoughts&lt;/strong&gt; by Gian-Carlo Rota&lt;/summary&gt;
  &lt;p&gt;The first half of this book (by a mathematician) consists of vivid personality sketches of the various mathematicians of Princeton from the mid 1900s, detailing their approach to research, lectures, and also their quirks and flaws. It&apos;s an entertaining read! I also like his essay about the cafe culture in Europe where mathematicians and philsophers would congregate to converse, conjecture and collaborate.&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;The Knowledge Machine&lt;/strong&gt; by Michael Strevens&lt;/summary&gt;
  &lt;p&gt;This book presents a theory of why science emerged when it did; what stood out to me are examples of scientists making irrational or un-objective decisions e.g., such as in the Eddington eclipse experiment where scientists ignored some data that might have otherwise tipped the scales in favor of Newton.&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;I received a few more suggestions from readers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ascent of Man&lt;/strong&gt; by Bronowski  (h/t Tarun Gupta)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Infinite Powers&lt;/strong&gt; by Steven Strogatz (h/t Puneesh Deora)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Emergence of Probability&lt;/strong&gt; by Ian Hacking and &lt;strong&gt;Science in history&lt;/strong&gt; by Bernal (h/t Javier Burroni)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Footnotes&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;While point 1 and 2 are inherent to science and research, the rest are idiosyncrasies of the current system of doing science. It does not have to be this way and I do not mean to normalize any of it, and I truly wish they were gone. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;There is another important dynamic you’ll notice in history, one which is less personal and more social:   science has interacted with politics in unfortunate and devastating ways causing great and unequal harms. This interaction goes in two ways. Science creates new political tension, and conversely, political tension both hastens and hinders science. This is a topic of its own and is important to pay attention to while you read! &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Most of these books are random picks from various old book stores, so they do not come vetted by popularity. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;My summaries are based off of memory so please actually read the book. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 29 Apr 2025 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/history-of-science/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/history-of-science/</guid>
      </item>
    
  </channel>
</rss>