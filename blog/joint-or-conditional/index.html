<html>
  <head>
    
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js", "TeX/noUndefined.js", "TeX/noErrors.js", "Safe.js", "html.js"], /* Ensure 'html.js' is here */
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreHtmlClass: 'no-mathjax',
      skipTags: ["script","noscript","style","textarea","pre","code","a"]
    },
    "HTML-CSS": {
      availableFonts: ["TeX"],
      linebreaks: { automatic: true },
      // --- KEY CHANGE 1: Enable linebreaks for HTML-CSS output ---
      linebreaks: { automatic: true },
      // --- KEY CHANGE 2: Define custom styles using CSS variables ---
      styles: {
        ".MathJax_Display": { // For display equations
          "background-color": "var(--mathjax-highlight-background)", // Default is transparent
          "color": "var(--mathjax-highlight-text)" // Default is black/white
        },
        ".MathJax_Display .MathJax_Math span": { // Target text within display equations
            "background-color": "inherit !important", /* Prevents MathJax from forcing background */
            "color": "var(--mathjax-highlight-text)" /* Ensure text color applies if you highlight entire blocks */
        },
        ".MathJax_Display .MathJax_Math": {
            "background-color": "inherit !important",
        },
        ".MathJax_SVG_Display": { // For SVG output (if enabled)
            "background-color": "var(--mathjax-highlight-background)",
            "color": "var(--mathjax-highlight-text)"
        },
        ".MathJax_SVG_Display svg": {
            "background-color": "inherit",
        },
        ".MathJax_SVG_Display .mjx-chtml": {
            "background-color": "inherit",
        },
        /* Define a custom class for highlighting within equations */
        ".highlighted-math": {
            "background-color": "var(--mathjax-highlight-background) !important",
            "color": "var(--mathjax-highlight-text) !important",
            "padding": "0.1em 0.3em", /* Add some padding around the highlight */
            "border-radius": "0.2em" /* Slightly rounded corners */
        }
      }
    },
    TeX: {
    Macros: { // Define custom LaTeX commands here
      highlightmath: ['{\\htmlclass{highlighted-math}{\\text{#1}}}', 1], // #1 means it takes one argument
      },
    equationNumbers: { autoNumber: "AMS" }, // This enables (1), (2), etc.
    extensions: ["AMSmath.js", "AMSsymbols.js"]
    },
    SVG: { linebreaks: { automatic: true } }, // Enable linebreaks for SVG output as well
    menuSettings: { zoom: "Double-Click" }
  });
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    <meta content='What does a language model model? - Vaishnavh Nagarajan' property='og:title' />
    <title>What does a language model model? - Vaishnavh Nagarajan</title>
    <!--
<script type='text/javascript'>
  //<![CDATA[
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', '']);
    _gaq.push(['_trackPageview']);
    
    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  //]]>
</script>
-->



<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TZ1W6KRGW0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-TZ1W6KRGW0');
</script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Roboto+Slab:wght@100..900&display=swap" rel="stylesheet">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous" referrerpolicy="no-referrer" />


<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">





<link href='https://fonts.googleapis.com/css?family=IM Fell DW Pica|IM Fell DW Pica SC|IM Fell English|IM Fell English SC|IM Fell French Canon|IM Fell Great Primer|IM Fell Great Primer SC|IM Fell Great Primer IT|IM Fell Double Pica|Libre Caslon Text|Jost|Instrument Serif' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=IM+Fell+Great+Primer:400,400i&display=swap' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Instrument+Serif:400,400i&display=swap' rel='stylesheet'>


<!--<link href='http://fonts.googleapis.com/css?family=Teko|Dosis:400,800|Economica|Josefin+Sans|Oswald|Indie+Flower|Pacifico|Roboto' rel='stylesheet' type='text/css'><link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css' /> -->
<link href='/stylesheets/style.css' rel='stylesheet' type='text/css' />
<link href='/stylesheets/syntax.css' rel='stylesheet' type='text/css' />
<link href='/stylesheets/responsive.css' rel='stylesheet' type='text/css' />
<!-- - -->
<script src='/javascripts/jquery.js' type='text/javascript'></script>
<script src='/javascripts/pd.js' type='text/javascript'></script>
<script src='/javascripts/basics.js' type='text/javascript'></script>
<script type="text/javascript" src="https://www.google.com/jsapi"></script>
<!-- - -->
<meta content='width=device-width, initial-scale=1.0' name='viewport'>
<meta content='text/html; charset=utf-8' http-equiv='content-type' />
<meta content="http://muan.co/images/og.png" property="og:image" />
<meta content="" property="fb:app_id" />

  <meta content='/blog/joint-or-conditional/' property='og:url' />
  <meta content="TL;DR: Does the next-token logit track the conditional or the joint probability of the whole sequence?I had an invisi..." property='og:description' />
  <meta content="article" property="og:type" />

<!-- - -->



<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1&appId=604714799556697";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>




  </head>
  <body>
    <header>
<!--<br><p>Vaishnavh Nagarajan</p>-->
</header>
    <div id='container'>
      <div class="content">
                    <nav>

  <div class="navigation">
    <div class="logo"><a href="/home/index.html">Vaishnavh Nagarajan</a></div>
    <div class="menu">

  
    <a href="/home/index.html"  class="link">
      <div class="title">
      About
    </div>
    </a>
  
    <a href="/home/index.html#research"  class="link">
      <div class="title">
      Research
    </div>
    </a>
  
    <a href="/talks/index.html"  class="link">
      <div class="title">
      Talks
    </div>
    </a>
  
    <a href="/blog/index.html"  class="link">
      <div class="title">
      Blog
    </div>
    </a>
  
    </div>
    <button id="theme-toggle-button" class="font-awesome-icons">
        <i id="theme-toggle-icon" class="fas fa-moon"></i>  <span class="visually-hidden">Toggle Dark Mode</span>
      </button>
  </div>
</nav>
        <section class='blog-post'>
          <br><br>
          <div class="blogtitle">What does a language model model?</div>


        <div class="blogbody"><p><strong>TL;DR: Does the next-token logit track the conditional or the joint probability of the whole sequence?</strong></p>

<p>I had an invisible <a href="https://en.wikipedia.org/wiki/The_Invisible_Gorilla">gorilla</a> moment while reading a paper. Even though the paper interprets the gorilla in a way I’m not in agreement with, in helping me notice something so basic that was staring at me all along, the paper led me closer to clarity. The paper is called “Spilled Energy in Large Language Models” by <a href="https://arxiv.org/abs/2602.18671">Robert et al., 2026</a><sup id="fnref:paper" role="doc-noteref"><a href="#fn:paper" class="footnote" rel="footnote">1</a></sup> which proposes a way to predict whether or not a generated token is hallucinated. The proposal is simple and cute: when you generate a token, if you’re suspicious of it, take the corresponding logit of that token as $\tt{Term} 1$; feed the suspicious token in and proceed to the next step, where you take the <em>denominator</em> of the softmax probability as $\tt{Term 2}$. If  $\tt{Term 2}$ is much smaller than $\tt{Term 1}$, your model has likely hallucinated. This difference quantity is what they call as “Spilled Energy”.</p>

<p>Specifically, if $f( \tt{token} ; \tt{context} )$ is my language model’s logit on a token given a context as input, if $x$ is my suspicious token, and $y’$ some next token candidate (I’ll save the symbol $y$ for later!), then:</p>

\[\begin{equation}
\textrm{Spilled Energy} = \underbrace{f(x ; \tt{context})}_{\tt{Term1}} - \underbrace{\log \sum_{y'} \exp(f( y' ; {\tt context}, x))}_{\tt{Term2}} 
\end{equation}\]

<p><img src="/assets/images/2026-02-27-joint-or-conditional/spilled_energy.jpg" alt="SpilledEnergy" class="theme-aware-img center-image" style="width: 40%;" /></p>

<p>First things first, I made sure this smelled good: ${\tt Term 1}$ reflects the enthusiasm<sup id="fnref:enthusiasm" role="doc-noteref"><a href="#fn:enthusiasm" class="footnote" rel="footnote">2</a></sup> of the model in predicting the suspicious token, ${\tt Term 2}$  the enthusiasm of the model in continuing that train of thought for one more step, summed over all possible continuations.  If the model abruptly turns unenthusiastic, it means that the model has found itself in a grave it enthusiastically dug one step ago. Makes sense. But is this handwavy justification all there is to it?</p>

<h3 id="the-papers-interpretation">The paper’s interpretation</h3>

<p>The paper offers a tighter justification. The joint probability that the model assigns to a sequence must be decomposible into next-token probabilities, a fact the reader should be able to blurt out in sleep:</p>

\[\require{color}
\begin{align}
  p({\tt context}, x, y) &amp; =  p({\tt context}) \cdot p(x | {\tt context}) \cdot p(y| {\tt context}, x) \\ 
  &amp; = p({\tt context}) \cdot \frac{\colorbox{silver}{$\color{black} p({\tt context}, x )$}}{p({\tt  context})} \cdot \frac{p({\tt context}, x, y)}{\colorbox{silver}{$\color{black} p({\tt context}, x )$}} \label{eq:dec1}
\end{align}\]

<p>Then comes the main claim: we’ve designed the next-token-predicting language model to capture these very next-token quantities; which means ideally every numerator and its subsequent denominator, as estimated by the model, should cancel out (our ${\tt Term1}$ and ${\tt Term 2}$). <em>Yet, the claim goes, nothing in a language model imposes this constraint on its estimates!</em> Specifically if we let $\hat{p}$ be the model’s assigned probability to a sequence, we can write it in a way (see Eq $\ref{eq:energy}$) that we can “superimpose” it against the above equation (Eq $\eqref{eq:dec1}$), to infer that ${\tt Term1}$ must match ${\tt Term2}$. When these Terms do not match in practice, we are to conclude that there is profoundly erratic behavior within the model, manifesting as hallucinations.</p>

\[\begin{align}
  \hat{p}({\tt context}, x, y) &amp; =  p({\tt context}) \cdot \frac{ 
  \overbrace{
  \colorbox{silver}{$\color{black}\exp{f(x; \tt{context})}$
  }}^{\propto \exp({\tt Term1})}}{\sum_{x'} \exp{f(x'; {\tt context})}} \cdot  \frac{ \exp{f(x; \tt{context})}}{\underbrace{
  \colorbox{silver}{$\color{black}\sum_{y'} \exp{f(y'; {\tt context}, x)}$}
  }_{\propto \exp(\tt Term2)}} \label{eq:energy} \\ 
\end{align}\]

<h3 id="my-interpretation">My interpretation</h3>

<p>This disturbed me: how had I missed a gorilla hiding in an object I had stared at for weeks at one point?<sup id="fnref:ntp" role="doc-noteref"><a href="#fn:ntp" class="footnote" rel="footnote">3</a></sup></p>

<p>A further staring contest somewhat resolved this confusion: I had never done the superimposition this way (and I wouldn’t do it this way). I had always superimposed Eq $\eqref{eq:energy}$ over a decomposition different from Eq $\ref{eq:dec1}$:</p>

\[\begin{align}
  p({\tt context}, x, y) 
  &amp; = p({\tt context}) \cdot \frac{p({\tt context} | x )}{\sum_{x'} p({x' | \tt  context})} \cdot \frac{p(y | {\tt context}, x)}{\sum_{y'} p(y' | {\tt context}, x)} \label{eq:w}
\end{align}\]

<p>In other words, I had always viewed the logits as representing how likely the next-token was, rather than how likely the whole sequence was! To me this was the obvious interpretation: we train a model on the “next-token loss” with the hope that it learns how good/bad that token is, with no care for how likely the input sequence is.</p>

<h3 id="its-not-that-clear-which-interpretation-is-correct">It’s not that clear which interpretation is correct.</h3>

<p>But then, I realize that this interpretation is not as clear-cut. While the next-token loss indeed stipulates what the <em>probabilities</em> must be (the conditionals), the <em>logit</em> magnitudes are underdetermined. Usually, in gradient-descent-trained models, if something is free to move as it pleases, it moves gracefully, and we may find this grace in the logits too. On seen contexts, a well-trained generative model’s logits will be forced to spike up (to $\infty$) on the seen next-token and spike down (to $-\infty$) everywhere else and so the “total energy” in  ${\tt Term 2}$ would explode. On completely bizarre contexts (say, due to our suspicious $x$ token), the next-token logits are “free to be what they want” and so, we may expect them to largely remain unenthusiastic (blunting ${\tt Term 2}$). In between these extremes, as we get closer and closer to the training manifold, we can expect the logits to be more and more enthusiastic on some next-tokens. This way, it seems that the total energy term in ${\tt Term 2}$ is indicative of the full $({\tt context}, x, y)$ sequence probability.</p>

<p>It’s funny that this argument can be applied to even make image classifiers appear as though they are models of the input distribution:  when your input image is garbage, the logits are likely tiny in magnitude; when you input image is realistic, the logits are higher in magnitude.</p>

<p>Now, I do not mean to say that these logits are exactly representative of the joint probability. On some reasonable inputs, the next-token logits may be unenthusiastic
purely due to poor learning resulting in lack of confidence on its next-token prediction. But what about a model that has perfectly learned the next-token conditionals?  Is its logits nicely representative of the joint distribution?</p>

<h3 id="the-question">The question</h3>

<p>My takeaway is this: surely, next-token probabilities of a model indeed only model the conditionals; but due to the implicit bias of gradient descent, it’s possible that the next-token logits reflect, to some extent, the joint probability of $({\tt context}, x)$, with some additional factors corresponding to the next-token confidence itself.  Is this just a feel-good empirical observation? Or is it possible to give this a mathematical form? Has someone already done this?</p>

<p>Maybe this gorilla was always visible and many knew;  or maybe this gorilla is just in my imagination; but for the time being, I will enjoy the feeling of having noticed it.</p>

<hr />

<p><strong>Footnotes</strong></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:paper" role="doc-endnote">
      <p>Spilled Energy in Large Language Models, Adrian Robert Minut, Hazem Dewidar, Iacopo Masi, 2026, <a href="https://arxiv.org/abs/2602.18671">https://arxiv.org/abs/2602.18671</a> <a href="#fnref:paper" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:enthusiasm" role="doc-endnote">
      <p>I use “enthusiasm” to avoid using “confidence” which usually refers to a probability value between 0 and 1. <a href="#fnref:enthusiasm" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:ntp" role="doc-endnote">
      <p>I remember staring at it when setting up the notations for “the pitfalls of next-token prediction” <a href="https://arxiv.org/abs/2403.06963">paper</a>, during which came the (obvious-sounding) realization that the next-token predicting backbone by itself does not define a joint distribution over a future sequence; it only defines the next-token distribution. It’s the autoregressive wrapper around it that defines the joint distribution; a different wrapper would yield a different joint! Sounds trivial, but disentangling this in our notation helped clean up our thoughts. <a href="#fnref:ntp" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
        </section>
      </div>

        <div class="post-navigation">
  
    <a href="/blog/high-dimensional-diff/" class="nav-arrow left-arrow">&laquo; Angles between high-dimensional vectors</a>
  

  
</div>

          <!-- <div class="block">
<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
<a class="a2a_button_x"></a>
<a class="a2a_button_google_gmail"></a>
<a class="a2a_button_threads"></a>
<a class="a2a_button_hacker_news"></a>
<a class="a2a_button_linkedin"></a>
<a class="a2a_button_reddit"></a>
<a class="a2a_button_facebook"></a>
<a class="a2a_button_mastodon"></a>
</div>
<script async src="https://static.addtoany.com/menu/page.js"></script>
</div> -->
      <!--  <div class="block">
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'http://localhost:4000/blog/joint-or-conditional/';
      this.page.identifier = 'http://localhost:4000/blog/joint-or-conditional/';
    };
    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://vaishnavh.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div> 
 -->

 

<div class="block">
  <div id="disqus_thread"></div>
  <script>
    // The original Disqus embed script. We now rely on the global disqus_config
    // defined above, and the reset logic in the theme toggler.
    // Ensure this script still runs to initially load Disqus.
    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://vaishnavh.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

    </div>




    <footer>

  <br />
  <script type="text/javascript" language="javascript">
  <!--
  // Email obfuscator script 2.1 by Tim Williams, University of Arizona
  // Random encryption key feature by Andrew Moulden, Site Engineering Ltd
  // This code is freeware provided these four comment lines remain intact
  // A wizard to generate this code is at http://www.jottings.com/obfuscator/
  //-->
  </script><noscript>first name AT google DOT com</noscript>



					<br />
					<br />
  Built with Jekyll using Scribble.
  <br>
  <img src="/images/scribble2.png " alt="scribble" /> 
</footer>
    <script type="text/javascript">
  document.addEventListener('DOMContentLoaded', function() {
    const themeToggleButton = document.getElementById('theme-toggle-button');
    const themeToggleIcon = document.getElementById('theme-toggle-icon');  // New: select the icon
    const body = document.body;
    const currentTheme = localStorage.getItem('theme');

    console.log('DOMContentLoaded fired');
    console.log('themeToggleButton:', themeToggleButton);
    console.log('body:', body);
    console.log('currentTheme:', currentTheme);

    // Define disqus_config globally or within a scope accessible by DISQUS.reset
    // A more robust way is to make it a named function or a property of window
    // so DISQUS.reset can find it.
   // so DISQUS.reset can find it.
    window.disqus_config = function () {
      this.page.url = 'http://localhost:4000/blog/joint-or-conditional/';
      this.page.identifier = 'http://localhost:4000/blog/joint-or-conditional/';

      // Get the current theme from your body's data-theme attribute
      var disqusTheme = localStorage.getItem('theme');

      // Set the Disqus theme based on your site's current theme
      if (currentThemeForDisqus === 'light') {
        this.page.display_thread_theme = 'light';
      } else {
        this.page.display_thread_theme = 'dark';
      }
    };

    
    const initializeTheme = () => {
      const themeToggleButton = document.getElementById('theme-toggle-button');
      const themeToggleIcon = document.getElementById('theme-toggle-icon');  // New: select the icon
      if (!themeToggleButton) {
        console.error('Dark mode toggle element not found!');
        return;
      }

      console.log('initializeTheme called, themeToggleButton:', themeToggleButton);

      // Set initial theme based on local storage
      if (currentTheme === 'light') {
        body.setAttribute('data-theme', 'light');
        themeToggleIcon.classList.remove('fa-sun');   // Switch to sun icon
        themeToggleIcon.classList.add('fa-moon');
        console.log('Setting light theme initially');
      } else {
        body.setAttribute('data-theme', 'dark');  // Default to dark
        themeToggleIcon.classList.remove('fa-moon');   // Switch to moon icon
        themeToggleIcon.classList.add('fa-sun');
        console.log('Setting default dark theme');
      }

      // Add event listener for toggle change
      themeToggleButton.addEventListener('click', function() {
        console.log('Toggle clicked');
        if (body.getAttribute('data-theme') === 'dark') {
          body.setAttribute('data-theme', 'light');
          localStorage.setItem('theme', 'light');
          themeToggleIcon.classList.remove('fa-sun');   // Switch to sun icon
          themeToggleIcon.classList.add('fa-moon');
        } else {
          body.setAttribute('data-theme', 'dark');
          localStorage.setItem('theme', 'dark');
          themeToggleIcon.classList.remove('fa-moon');   // Switch to moon icon
          themeToggleIcon.classList.add('fa-sun');
        }
        console.log('body.getAttribute("data-theme"):', body.getAttribute('data-theme'));

        // --- NEW: Reset Disqus theme after the site theme changes ---
        if (typeof DISQUS !== 'undefined') { // Check if Disqus is loaded
          DISQUS.reset({
            reload: true, // This tells Disqus to reload the embed
            config: function () {
              // Re-run the configuration to apply the new theme
              // This relies on window.disqus_config being accessible
              window.disqus_config.call(this);
            }
          });
          console.log('Disqus reset initiated with new theme.');
        }
        // --- END NEW ---
      });
    };

    if (document.readyState === 'loading') {
      document.addEventListener('readystatechange', function() {
        if (document.readyState === 'interactive' || document.readyState === 'complete') {
          initializeTheme();
        }
      });
      console.log('readyState is loading, adding readystatechange listener');
    } else {
      initializeTheme();
      console.log('readyState is not loading, calling initializeTheme directly');
    }
  });
</script>
<script src="/assets/js/footnotes.js"></script>
  </body>
</html>
